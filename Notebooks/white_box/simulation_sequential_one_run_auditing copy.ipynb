{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ad1fe543",
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "import json\n",
        "import secrets\n",
        "import numpy as np\n",
        "\n",
        "# Navigate to the parent directory of the project structure\n",
        "project_dir = os.path.abspath(os.path.join(os.getcwd(), '../../'))\n",
        "src_dir = os.path.join(project_dir, 'src')\n",
        "data_dir = os.path.join(project_dir, 'data')\n",
        "fig_dir = os.path.join(project_dir, 'fig')\n",
        "logs_dir = os.path.join(project_dir, 'logs')\n",
        "os.makedirs(fig_dir, exist_ok=True)\n",
        "os.makedirs(data_dir, exist_ok=True)\n",
        "os.makedirs(logs_dir, exist_ok=True)\n",
        "\n",
        "# Add the src directory to sys.path\n",
        "sys.path.append(src_dir)\n",
        "\n",
        "import torch\n",
        "from opacus import PrivacyEngine\n",
        "import torch.optim as optim\n",
        "\n",
        "from dataset import get_auditable_data_loaders, generate_poisoned_canaries_and_mask\n",
        "from network_arch import WideResNet\n",
        "from classifier.white_box_dp_sgd import sample_gaussian, sample_mixture, ThresholdAuditor\n",
        "from classifier.white_box_dp_sgd import GaussianLLRAuditor, MixtureSequenceLLRAuditor\n",
        "from utils import setup_logging\n",
        "from auditing import CanaryScoreAuditor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "7e799383",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "# Hyperparameters (Settings from the paper \"Unlocking High-Accuracy Differentially Private Image Classification through Scale\")\n",
        "# ==========================================\n",
        "LOGICAL_BATCH_SIZE = 4096     # Target batch size (Paper)\n",
        "MAX_PHYSICAL_BATCH_SIZE = 128  # GPU limit (128 * 16 = 512 effective images)\n",
        "AUG_MULTIPLICITY = 16         # K=16 augmentations\n",
        "MAX_GRAD_NORM = 1.0\n",
        "EPSILON = 8.0\n",
        "DELTA = 1e-5\n",
        "EPOCHS = 200                   # Increase to 100+ for best results\n",
        "LR = 4.0                      # High LR for large batch\n",
        "MOMENTUM = 0.0                # No momentum\n",
        "NOISE_MULTIPLIER = 3.0        # Sigma ~ 3.0 is optimal for BS=4096\n",
        "CKPT_INTERVAL = 20            # Save checkpoint every 10 epochs\n",
        "\n",
        "\n",
        "# ==========================================\n",
        "# Experiment Parameters\n",
        "# ==========================================\n",
        "CANARY_COUNT = 5000           # Number of canaries\n",
        "PKEEP = 0.5                   # Probability of including each canary in the training set\n",
        "DATABSEED = 53841938803364779163249839521218793645  # if seed is set to None then seed is random\n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "7291bdf0",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2026-02-02 20:53:22 - INFO - Logging initialized. Log file: /storage/coda1/p-vzikas3/0/ywei368/Yu-Project/Auditing/dpsgd-auditbench/logs/train_20260202_205322.log\n",
            "2026-02-02 20:53:22 - INFO - Experiment directory: /storage/coda1/p-vzikas3/0/ywei368/Yu-Project/Auditing/dpsgd-auditbench/data/white-box-canaries-53841938803364779163249839521218793645-5000-0.5-cifar10\n",
            "2026-02-02 20:53:22 - INFO - Checkpoint directory: /storage/coda1/p-vzikas3/0/ywei368/Yu-Project/Auditing/dpsgd-auditbench/data/white-box-canaries-53841938803364779163249839521218793645-5000-0.5-cifar10/ckpt\n",
            "2026-02-02 20:53:22 - INFO - Run experiment on device: cuda\n",
            "2026-02-02 20:53:22 - INFO - Set random seeds (torch, numpy) to: 1171924545 (from DATABSEED: 53841938803364779163249839521218793645)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2026-02-02 20:53:22 - INFO - Hyperparameters saved to: /storage/coda1/p-vzikas3/0/ywei368/Yu-Project/Auditing/dpsgd-auditbench/data/white-box-canaries-53841938803364779163249839521218793645-5000-0.5-cifar10/hparams.json\n"
          ]
        }
      ],
      "source": [
        "logger, log_file = setup_logging(log_dir=logs_dir)\n",
        "logdir_path = os.path.dirname(log_file) \n",
        "\n",
        "# Create experiment directory\n",
        "if DATABSEED is not None:\n",
        "    exp_dir = os.path.join(data_dir, f\"white-box-canaries-{DATABSEED}-{CANARY_COUNT}-{PKEEP}-cifar10\")\n",
        "else:\n",
        "    DATABSEED = secrets.randbits(128)\n",
        "    logger.info(f\"Generated random 128-bit seed: {DATABSEED}\")\n",
        "    exp_dir = os.path.join(data_dir, f\"white-box-canaries-{DATABSEED}-{CANARY_COUNT}-{PKEEP}-cifar10\")\n",
        "\n",
        "os.makedirs(exp_dir, exist_ok=True)\n",
        "logger.info(f\"Experiment directory: {exp_dir}\")\n",
        "\n",
        "# Create checkpoint directory under experiment directory\n",
        "ckpt_dir = os.path.join(exp_dir, \"ckpt\")\n",
        "os.makedirs(ckpt_dir, exist_ok=True)\n",
        "logger.info(f\"Checkpoint directory: {ckpt_dir}\")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "logger.info(f\"Run experiment on device: {device}\")\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "# Cast 128-bit seed to 64-bit for PyTorch compatibility\n",
        "torch_seed = int(DATABSEED % (2**32 - 1))\n",
        "np_seed = int(DATABSEED % (2**32 - 1))\n",
        "torch.manual_seed(torch_seed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(torch_seed)\n",
        "    torch.cuda.manual_seed_all(torch_seed)\n",
        "np.random.seed(np_seed)\n",
        "logger.info(f\"Set random seeds (torch, numpy) to: {torch_seed} (from DATABSEED: {DATABSEED})\")\n",
        "\n",
        "# Store hyperparameters in a dictionary\n",
        "params = {\n",
        "    'logical_batch_size': LOGICAL_BATCH_SIZE,\n",
        "    'max_physical_batch_size': MAX_PHYSICAL_BATCH_SIZE,\n",
        "    'aug_multiplicity': AUG_MULTIPLICITY,\n",
        "    'max_grad_norm': MAX_GRAD_NORM,\n",
        "    'epsilon': EPSILON,\n",
        "    'delta': DELTA,\n",
        "    'epochs': EPOCHS,\n",
        "    'lr': LR,\n",
        "    'momentum': MOMENTUM,\n",
        "    'noise_multiplier': NOISE_MULTIPLIER,\n",
        "    'ckpt_interval': CKPT_INTERVAL,\n",
        "    'canary_count': CANARY_COUNT,\n",
        "    'pkeep': PKEEP,\n",
        "    'database_seed': DATABSEED\n",
        "}\n",
        "\n",
        "# Save hyperparameters to experiment directory\n",
        "hparams_path = os.path.join(exp_dir, 'hparams.json')\n",
        "with open(hparams_path, 'w') as f:\n",
        "    json.dump(params, f, indent=2)\n",
        "logger.info(f\"Hyperparameters saved to: {hparams_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "f159ec11",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading canary database and mask...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/python-venv/dpsgd-auditbench_venv/lib/python3.12/site-packages/torchvision/datasets/cifar.py:83: VisibleDeprecationWarning: dtype(): align should be passed as Python or NumPy boolean but got `align=0`. Did you mean to pass a tuple to create a subarray type? (Deprecated NumPy 2.4)\n",
            "  entry = pickle.load(f, encoding=\"latin1\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 5000 total canaries\n",
            "  - In-canaries (included in training): 2512\n",
            "  - Out-canaries (excluded from training): 2488\n",
            "Loading data...\n"
          ]
        }
      ],
      "source": [
        "# Load canary database and mask\n",
        "print(\"Loading canary database and mask...\")\n",
        "poisoned_canaries, inclusion_mask = generate_poisoned_canaries_and_mask(\n",
        "    data_dir=data_dir,\n",
        "    canary_count=CANARY_COUNT,\n",
        "    seed=DATABSEED,\n",
        "    pkeep=PKEEP\n",
        ")\n",
        "\n",
        "print(f\"Loaded {len(poisoned_canaries)} total canaries\")\n",
        "out_canary_count = np.sum(~inclusion_mask)\n",
        "in_canary_count = np.sum(inclusion_mask)\n",
        "print(f\"  - In-canaries (included in training): {out_canary_count}\")\n",
        "print(f\"  - Out-canaries (excluded from training): {in_canary_count}\")\n",
        "\n",
        "print(\"Loading data...\")\n",
        "train_dataset, test_dataset = get_auditable_data_loaders(\n",
        "    data_dir=data_dir,\n",
        "    canary_count=CANARY_COUNT,\n",
        "    seed=DATABSEED,\n",
        "    pkeep=PKEEP\n",
        ")\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset, batch_size=LOGICAL_BATCH_SIZE, shuffle=True, num_workers=4, drop_last=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "67520ba9",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create initial model for score computation (only once)\n",
        "torch_seed = int(DATABSEED % (2**32 - 1))\n",
        "np_seed = int(DATABSEED % (2**32 - 1))\n",
        "torch.manual_seed(torch_seed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(torch_seed)\n",
        "    torch.cuda.manual_seed_all(torch_seed)\n",
        "np.random.seed(np_seed)\n",
        "initial_model = WideResNet(depth=16, widen_factor=4).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "902337c8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2026-02-02 20:53:27 - WARNING - Ignoring drop_last as it is not compatible with DPDataLoader.\n",
            "Sampling rate sample_rate = 0.090909\n",
            "Steps/epoch (drop_last) = 11\n",
            "Score noise sigma = noise_multiplier * max_grad_norm = 3.000000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/python-venv/dpsgd-auditbench_venv/lib/python3.12/site-packages/opacus/privacy_engine.py:96: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "optimizer = optim.SGD(initial_model.parameters(), lr=LR, momentum=MOMENTUM)\n",
        "\n",
        "# Setup privacy engine\n",
        "privacy_engine = PrivacyEngine()\n",
        "model, optimizer, train_loader = privacy_engine.make_private(\n",
        "    module=initial_model,\n",
        "    optimizer=optimizer,\n",
        "    data_loader=train_loader,\n",
        "    noise_multiplier=NOISE_MULTIPLIER,\n",
        "    max_grad_norm=MAX_GRAD_NORM,\n",
        ")\n",
        "\n",
        "steps_per_epoch = len(train_loader) \n",
        "sample_rate = 1 / len(train_loader)\n",
        "sigma = NOISE_MULTIPLIER*MAX_GRAD_NORM\n",
        "\n",
        "print(f\"Sampling rate sample_rate = {sample_rate:.6f}\")\n",
        "print(f\"Steps/epoch (drop_last) = {steps_per_epoch}\")\n",
        "print(f\"Score noise sigma = noise_multiplier * max_grad_norm = {sigma:.6f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4a61710",
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'eps_lb_seq' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 38\u001b[39m\n\u001b[32m     35\u001b[39m     threshold_lower_bounds.append(eps_lb_threshold)\n\u001b[32m     36\u001b[39m     gaussian_llr_lower_bounds.append(eps_lb_llr)\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: Upper bound = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_eps\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, NIPS 23 = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00meps_lb_default\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Threshold = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00meps_lb_threshold\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Gaussian LLR = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00meps_lb_llr\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Sequence LLR = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43meps_lb_seq\u001b[49m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# Plot the bounds\u001b[39;00m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n",
            "\u001b[31mNameError\u001b[39m: name 'eps_lb_seq' is not defined"
          ]
        }
      ],
      "source": [
        "# Initialize lists to store bounds\n",
        "epoch_list = []\n",
        "upper_bounds = []  \n",
        "default_lower_bounds = []  \n",
        "threshold_lower_bounds = []  \n",
        "gaussian_llr_lower_bounds = []\n",
        "sequence_llr_lower_bounds = []\n",
        "\n",
        "# Load scores from mislabeled-canaries experiment (in_scores_*.csv, out_scores_*.csv per epoch)\n",
        "SCORE_EXP_DIR = os.path.join(data_dir, \"mislabeled-canaries-27198899012190525004019618245709479116-10000-0.5-cifar10\")\n",
        "\n",
        "for epochs in range(CKPT_INTERVAL, EPOCHS + 1, CKPT_INTERVAL):\n",
        "    steps = steps_per_epoch * epochs\n",
        "\n",
        "    privacy_engine.accountant.history.clear()\n",
        "    privacy_engine.accountant.history.append((NOISE_MULTIPLIER, sample_rate, steps))\n",
        "    current_eps = privacy_engine.get_epsilon(DELTA)\n",
        "\n",
        "    in_scores = np.loadtxt(os.path.join(SCORE_EXP_DIR, f\"in_scores_{epochs:06d}.csv\"))\n",
        "    out_scores = np.loadtxt(os.path.join(SCORE_EXP_DIR, f\"out_scores_{epochs:06d}.csv\"))\n",
        "\n",
        "    auditor = CanaryScoreAuditor(in_scores, out_scores)\n",
        "    eps_lb_default = auditor.epsilon_one_run(significance=0.05, delta=DELTA)\n",
        "\n",
        "    auditor = ThresholdAuditor(in_scores, out_scores)\n",
        "    eps_lb_threshold, _ = auditor.epsilon_one_run(delta=DELTA, smoothing=\"jeffreys\", return_details=True)\n",
        "\n",
        "    auditor = GaussianLLRAuditor(in_scores, out_scores, steps, sample_rate, MAX_GRAD_NORM, sigma)\n",
        "    eps_lb_llr, _ = auditor.epsilon_one_run(delta=DELTA, smoothing=\"jeffreys\", return_details=True)\n",
        "\n",
        "    # Store values\n",
        "    epoch_list.append(epochs)\n",
        "    upper_bounds.append(current_eps)\n",
        "    default_lower_bounds.append(eps_lb_default)\n",
        "    threshold_lower_bounds.append(eps_lb_threshold)\n",
        "    gaussian_llr_lower_bounds.append(eps_lb_llr)\n",
        "\n",
        "    print(f\"Epoch {epochs}: Upper bound = {current_eps:.2f}, NIPS 23 = {eps_lb_default:.2f}, Threshold = {eps_lb_threshold:.2f}, Gaussian LLR = {eps_lb_llr:.2f}\")\n",
        "\n",
        "# Plot the bounds\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(epoch_list, upper_bounds, marker='o', label='Upper bound (current_eps)', color='blue', linewidth=2)\n",
        "plt.plot(epoch_list, default_lower_bounds, marker='s', label='NIPS 23', color='red', linewidth=2)\n",
        "plt.plot(epoch_list, threshold_lower_bounds, marker='s', label='Threshold', color='green', linewidth=2)\n",
        "# plt.plot(epoch_list, gaussian_llr_lower_bounds, marker='s', label='Gaussian LLR', color='purple', linewidth=2)\n",
        "# plt.plot(epoch_list, sequence_llr_lower_bounds, marker='s', label='Sequence LLR', color='orange', linewidth=2)\n",
        "plt.xlabel('Epoch', fontsize=12)\n",
        "plt.ylabel('Epsilon', fontsize=12)\n",
        "plt.title('Privacy Bounds: Upper (theoretical) vs Lower (empirical audit)', fontsize=14)\n",
        "plt.legend(fontsize=11)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "\n",
        "# Save the figure\n",
        "fig_path = os.path.join(fig_dir, 'privacy_bounds_comparison.png')\n",
        "plt.savefig(fig_path, dpi=300, bbox_inches='tight')\n",
        "print(f\"\\nFigure saved to: {fig_path}\")\n",
        "\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08471c3b",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
